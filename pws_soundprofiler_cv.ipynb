{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "H7orHLjeZnLy",
        "VICWB3B1ZpuS",
        "rBImewkKZ4fn",
        "gKNGJMafXblV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthik-Kundurthy/pws-soundprofiler-cv/blob/main/pws_soundprofiler_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"\""
      ],
      "metadata": {
        "id": "sDLEIi6nJ23W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"\""
      ],
      "metadata": {
        "id": "vF6kq4iQJ7WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHuoXKmoExTG",
        "outputId": "c01dd0c5-678a-4d04-f623-a96358ffb9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pws-soundprofiler-ai'...\n",
            "remote: Enumerating objects: 39447, done.\u001b[K\n",
            "remote: Counting objects: 100% (1618/1618), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1580/1580), done.\u001b[K\n",
            "remote: Total 39447 (delta 44), reused 1549 (delta 32), pack-reused 37829\u001b[K\n",
            "Receiving objects: 100% (39447/39447), 867.27 MiB | 34.69 MiB/s, done.\n",
            "Resolving deltas: 100% (170/170), done.\n",
            "Checking out files: 100% (37782/37782), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://[token]@github.gatech.edu/Aquabots-VIP/pws-soundprofiler-ai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pws-soundprofiler-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8xETE8OKr20",
        "outputId": "b64c0923-3c9a-4add-85b8-4464199185dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pws-soundprofiler-ai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from data_generator import DataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "KIl5hGNWK033"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pc2RJvMNNNG4",
        "outputId": "bb1e2fcf-29a4-4f1c-e58f-100c4acc73fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Single CLS\n",
        "n_classes = 43\n",
        "input_shape = (299, 299, 3)\n",
        "feat_shape = (16,)\n",
        "\n",
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./logs', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'inception_v3_training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'inception_v3_validation')\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.create_file_writer(self.val_log_dir)       \n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        # for name, value in val_logs.items():\n",
        "        #     summary = tf.Summary()\n",
        "        #     summary_value = summary.value.add()\n",
        "        #     summary_value.simple_value = value.item()\n",
        "        #     summary_value.tag = name\n",
        "        #     self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "def get_single_cls_model():\n",
        "\n",
        "    pretrain_model = tf.keras.applications.InceptionV3(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "    input_image = Input(shape=input_shape)\n",
        "    x = pretrain_model(input_image)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    c1 = Dense(256-feat_shape[0], activation='relu')(x)\n",
        "    c2 = Input(shape=feat_shape)\n",
        "    c = Concatenate(axis=-1,)([c1, c2])\n",
        "    x = BatchNormalization()(c)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    output = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model([input_image, c2], output)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(1e-3),\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_single_cls_model_custom(pretrain_model, dense_dimension=512, lr=1e-3):\n",
        "    for layer in pretrain_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    input_image = Input(shape=input_shape)\n",
        "    x = pretrain_model(input_image)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Dense(dense_dimension, activation='relu')(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    c1 = Dense(256-feat_shape[0], activation='relu')(x)\n",
        "    c2 = Input(shape=feat_shape)\n",
        "    c = Concatenate(axis=-1,)([c1, c2])\n",
        "    x = BatchNormalization()(c)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    output = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model([input_image, c2], output)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(lr),\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def check_dirs(dirs):\n",
        "    for d in dirs:\n",
        "        exists = os.path.join(os.getcwd(), d)\n",
        "        if os.path.isdir(exists) is False:\n",
        "            os.mkdir(exists)"
      ],
      "metadata": {
        "id": "SDHGTdwXMBdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking dirs')\n",
        "check_dirs(['logs', 'models'])\n",
        "print('Loading class map')\n",
        "with open('class_map.p', 'rb') as handle:\n",
        "    class_map = pickle.load(handle)\n",
        "print('Loading plankton.csv')\n",
        "df = pd.read_csv('plankton.csv')\n",
        "df.drop_duplicates(subset='im_name', inplace=True, keep=False)\n",
        "\n",
        "params = {'n_classes': n_classes,\n",
        "          'shape': input_shape,\n",
        "          'feat_shape': feat_shape,\n",
        "          'batch_size': 64,\n",
        "          'shuffle': True}\n",
        "\n",
        "frames = []\n",
        "for c in np.unique(df.label):\n",
        "    frames.append(df[df.label==c].sample(n=5000, replace=True, random_state=0))\n",
        "df_sample = pd.concat(frames)\n",
        "\n",
        "paths = []\n",
        "labels = []\n",
        "data_path = os.path.join(os.getcwd(), 'pad')\n",
        "print('Creating labelled images')\n",
        "for im_name, label in zip(df_sample.im_name, df_sample.label):\n",
        "    im_dir = os.path.join(data_path, class_map[label])\n",
        "    im_path = os.path.join(im_dir, im_name)\n",
        "    paths.append(im_path)\n",
        "    labels.append(to_categorical(y=label, num_classes=n_classes))\n",
        "\n",
        "paths = np.array(paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(paths, labels, test_size=0.1, random_state=0)\n",
        "\n",
        "checkpoint = ModelCheckpoint('./models/inception_v3.model', monitor='val_acc', verbose=1, mode='max',\n",
        "                             save_best_only=True, save_weights_only=False, period=1)\n",
        "\n",
        "reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                                    patience=3, verbose=1, mode='min')\n",
        "\n",
        "tensorboard = TrainValTensorBoard(write_graph=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_QZ5yx9MF5b",
        "outputId": "99ac81ba-778b-4907-ec00-5173e00c1312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dirs\n",
            "Loading class map\n",
            "Loading plankton.csv\n",
            "Creating labelled images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert Model Template"
      ],
      "metadata": {
        "id": "ltRicrUWayxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.'''Put your own net here'''(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "mvVM_M3x0VpD",
        "outputId": "e9d92b3f-8038-4bd4-c559-ae84afdc1608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-64ca5ba22aff>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pretrain_model = tf.keras.applications.'''Put your own net here'''(\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNetB3"
      ],
      "metadata": {
        "id": "jrVJoW7ZZiAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.EfficientNetB3(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "id": "YGupTlqI6gam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xception"
      ],
      "metadata": {
        "id": "H7orHLjeZnLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.Xception(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "id": "tiT78Cdafyrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "f3d17442-6b64-40bc-d2e5-776df0bd9d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            " 4202496/83683744 [>.............................] - ETA: 1s"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b120c6d95597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Insert your own model here. For a list, visit https://keras.io/api/applications/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pretrain_model = tf.keras.applications.Xception(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         input_shape=input_shape)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/applications/xception.py\u001b[0m in \u001b[0;36mXception\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    303\u001b[0m           file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n\u001b[1;32m    304\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m       weights_path = data_utils.get_file(\n\u001b[0m\u001b[1;32m    306\u001b[0m           \u001b[0;34m'xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m           \u001b[0mTF_WEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLProgbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlretrieve\u001b[0m  \u001b[0;31m# pylint: disable=g-importing-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "VICWB3B1ZpuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "id": "-YgQkDgpMEan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## DenseNet121"
      ],
      "metadata": {
        "id": "rBImewkKZ4fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.DenseNet121(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U5x0hLpBZ5DR",
        "outputId": "8f0a0117-1e06-44c2-aa64-2729c70dc91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " densenet121 (Functional)       (None, 9, 9, 1024)   7037504     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1024)        0           ['densenet121[0][0]']            \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          524800      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512)         2048        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 240)          123120      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256)          0           ['dense_1[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256)         1024        ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           16448       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64)          256         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 43)           2795        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,707,995\n",
            "Trainable params: 668,827\n",
            "Non-trainable params: 7,039,168\n",
            "__________________________________________________________________________________________________\n",
            "Training model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.1291 - acc: 0.4216\n",
            "Epoch 1: val_acc improved from -inf to 0.61744, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 283s 875ms/step - loss: 2.1291 - acc: 0.4216 - val_loss: 1.3015 - val_acc: 0.6174\n",
            "Epoch 2/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.4513 - acc: 0.5778\n",
            "Epoch 2: val_acc improved from 0.61744 to 0.66670, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 299s 991ms/step - loss: 1.4513 - acc: 0.5778 - val_loss: 1.0951 - val_acc: 0.6667\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2e3092e035f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     callbacks=[tensorboard, checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2274\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1395\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Efficient Net V2L\n"
      ],
      "metadata": {
        "id": "gKNGJMafXblV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.EfficientNetV2L(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J0z3bLgWWDC",
        "outputId": "ee33d4ef-3870-4627-9e23-8059c4e31b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n",
            "473176280/473176280 [==============================] - 15s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " efficientnetv2-l (Functional)  (None, 10, 10, 1280  117746848   ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['efficientnetv2-l[0][0]']       \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          655872      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512)         2048        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 240)          123120      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256)          0           ['dense_1[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256)         1024        ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           16448       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64)          256         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 43)           2795        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 118,548,411\n",
            "Trainable params: 799,899\n",
            "Non-trainable params: 117,748,512\n",
            "__________________________________________________________________________________________________\n",
            "Training model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 3.2099 - acc: 0.1514\n",
            "Epoch 1: val_acc improved from -inf to 0.25634, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 339). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 1158s 4s/step - loss: 3.2099 - acc: 0.1514 - val_loss: 2.8760 - val_acc: 0.2563\n",
            "Epoch 2/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.5345 - acc: 0.2905\n",
            "Epoch 2: val_acc improved from 0.25634 to 0.37332, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 339). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 1116s 4s/step - loss: 2.5345 - acc: 0.2905 - val_loss: 2.2231 - val_acc: 0.3733\n",
            "Epoch 3/10\n",
            "183/302 [=================>............] - ETA: 2:46 - loss: 2.2970 - acc: 0.3408"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.InceptionV3(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B43G_XKdyI10",
        "outputId": "4685a8ab-f786-4e45-bc67-0a7910116018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " inception_v3 (Functional)      (None, 8, 8, 2048)   21802784    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['inception_v3[0][0]']           \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            2049        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 1)           4           ['dense[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 240)          480         ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256)          0           ['dense_1[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 256)         1024        ['concatenate_2[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           16448       ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 64)          256         ['dense_2[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 43)           2795        ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,825,840\n",
            "Trainable params: 22,414\n",
            "Non-trainable params: 21,803,426\n",
            "__________________________________________________________________________________________________\n",
            "Training model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.8655 - acc: 0.2251\n",
            "Epoch 1: val_acc improved from -inf to 0.16875, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 273s 854ms/step - loss: 2.8655 - acc: 0.2251 - val_loss: 3.1024 - val_acc: 0.1688\n",
            "Epoch 2/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.2897 - acc: 0.3514\n",
            "Epoch 2: val_acc improved from 0.16875 to 0.34888, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 248s 822ms/step - loss: 2.2897 - acc: 0.3514 - val_loss: 2.2578 - val_acc: 0.3489\n",
            "Epoch 3/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.1167 - acc: 0.3903"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mobile Net V2\n"
      ],
      "metadata": {
        "id": "EwZ1_LsJfNPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hNYYT3OtfQzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your own model here. For a list, visit https://keras.io/api/applications/ \n",
        "pretrain_model = tf.keras.applications.MobileNetV2(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape)\n",
        "\n",
        "#Change the below line\n",
        "model = get_single_cls_model_custom(pretrain_model, 1e-3)\n",
        "\n",
        "tg = DataGenerator(paths=X_train, labels=y_train, augment=True, **params)\n",
        "vg = DataGenerator(paths=X_val, labels=y_val, **params)\n",
        "#model = load_model('./models/inception_v3.model')\n",
        "print('Training model:')\n",
        "hist=model.fit_generator(generator=tg, validation_data=vg,\n",
        "                    steps_per_epoch=len(tg)/10, validation_steps=len(vg),\n",
        "                    epochs=10, verbose=1,\n",
        "                    callbacks=[tensorboard, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOuviVXvfQlZ",
        "outputId": "b34c13db-7470-4b49-ef5e-6dedc2671382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " mobilenetv2_1.00_224 (Function  (None, 10, 10, 1280  2257984    ['input_3[0][0]']                \n",
            " al)                            )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['mobilenetv2_1.00_224[0][0]']   \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 0)            0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 0)           0           ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 240)          240         ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256)          0           ['dense_1[0][0]',                \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 256)         1024        ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           16448       ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64)          256         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 43)           2795        ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,278,747\n",
            "Trainable params: 20,123\n",
            "Non-trainable params: 2,258,624\n",
            "__________________________________________________________________________________________________\n",
            "Training model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b8f2ba520383>:14: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist=model.fit_generator(generator=tg, validation_data=vg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.7445 - acc: 0.2623\n",
            "Epoch 1: val_acc improved from -inf to 0.14953, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 214s 673ms/step - loss: 2.7445 - acc: 0.2623 - val_loss: 3.0791 - val_acc: 0.1495\n",
            "Epoch 2/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.2356 - acc: 0.3671\n",
            "Epoch 2: val_acc improved from 0.14953 to 0.39520, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 200s 661ms/step - loss: 2.2356 - acc: 0.3671 - val_loss: 2.1836 - val_acc: 0.3952\n",
            "Epoch 3/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.1099 - acc: 0.3944\n",
            "Epoch 3: val_acc improved from 0.39520 to 0.41063, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 201s 667ms/step - loss: 2.1099 - acc: 0.3944 - val_loss: 2.0201 - val_acc: 0.4106\n",
            "Epoch 4/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 2.0408 - acc: 0.4040\n",
            "Epoch 4: val_acc improved from 0.41063 to 0.43671, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 202s 668ms/step - loss: 2.0408 - acc: 0.4040 - val_loss: 1.9388 - val_acc: 0.4367\n",
            "Epoch 5/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.9629 - acc: 0.4268\n",
            "Epoch 5: val_acc improved from 0.43671 to 0.44114, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 204s 674ms/step - loss: 1.9629 - acc: 0.4268 - val_loss: 1.9063 - val_acc: 0.4411\n",
            "Epoch 6/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.9334 - acc: 0.4317\n",
            "Epoch 6: val_acc improved from 0.44114 to 0.45686, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 202s 669ms/step - loss: 1.9334 - acc: 0.4317 - val_loss: 1.8406 - val_acc: 0.4569\n",
            "Epoch 7/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.8969 - acc: 0.4361\n",
            "Epoch 7: val_acc did not improve from 0.45686\n",
            "302/302 [==============================] - 184s 609ms/step - loss: 1.8969 - acc: 0.4361 - val_loss: 1.8519 - val_acc: 0.4538\n",
            "Epoch 8/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.8653 - acc: 0.4454\n",
            "Epoch 8: val_acc improved from 0.45686 to 0.46315, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 200s 663ms/step - loss: 1.8653 - acc: 0.4454 - val_loss: 1.8159 - val_acc: 0.4632\n",
            "Epoch 9/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.8343 - acc: 0.4528\n",
            "Epoch 9: val_acc improved from 0.46315 to 0.48372, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 199s 660ms/step - loss: 1.8343 - acc: 0.4528 - val_loss: 1.7362 - val_acc: 0.4837\n",
            "Epoch 10/10\n",
            "303/302 [==============================] - ETA: 0s - loss: 1.8101 - acc: 0.4538\n",
            "Epoch 10: val_acc improved from 0.48372 to 0.49109, saving model to ./models/inception_v3.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r302/302 [==============================] - 200s 663ms/step - loss: 1.8101 - acc: 0.4538 - val_loss: 1.7038 - val_acc: 0.4911\n"
          ]
        }
      ]
    }
  ]
}